{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-b695045f7ad6>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-ab8903634728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    294\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 296\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-b695045f7ad6>:2 "
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(\"cubo_ventas/fact_item.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes = sqlContext.read.format(\"csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(\"cubo_ventas/dim_customer.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order = sqlContext.read.format(\"csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(\"cubo_ventas/dim_order.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalog = sqlContext.read.format(\"csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(\"cubo_ventas/dim_catalog.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dwh_country_id='276', fk_sales_order_item='88056', fk_sales_order='5642', local_unit_price='1.29', unit_price_eur='1.29', local_tax_amount='0.08', tax_amount_eur='0.08', local_paid_price='1.29', paid_price_eur='1.29', local_paid_price_net='1.21', paid_price_net_eur='1.21', local_coupon_money_value='0', coupon_money_value_eur='0', local_coupon_money_value_net='0', coupon_money_value_eur_net='0', local_original_price='1.29', original_unit_price_eur='0.89', fk_dim_catalog='1676', fk_dim_date='9/28/2015 12:00:00 AM', fk_dim_customer='194', fk_dim_order='6142', order_bi_created_at='9/28/2015 8:33:17 AM', order_bi_updated_at='1/26/2016 3:55:59 PM', order_item_bi_created_at='9/28/2015 8:33:17 AM', order_item_bi_updated_at='9/28/2015 8:34:04 AM')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dwh_country_id: string (nullable = true)\n",
      " |-- fk_sales_order_item: string (nullable = true)\n",
      " |-- fk_sales_order: string (nullable = true)\n",
      " |-- local_unit_price: string (nullable = true)\n",
      " |-- unit_price_eur: string (nullable = true)\n",
      " |-- local_tax_amount: string (nullable = true)\n",
      " |-- tax_amount_eur: string (nullable = true)\n",
      " |-- local_paid_price: string (nullable = true)\n",
      " |-- paid_price_eur: string (nullable = true)\n",
      " |-- local_paid_price_net: string (nullable = true)\n",
      " |-- paid_price_net_eur: string (nullable = true)\n",
      " |-- local_coupon_money_value: string (nullable = true)\n",
      " |-- coupon_money_value_eur: string (nullable = true)\n",
      " |-- local_coupon_money_value_net: string (nullable = true)\n",
      " |-- coupon_money_value_eur_net: string (nullable = true)\n",
      " |-- local_original_price: string (nullable = true)\n",
      " |-- original_unit_price_eur: string (nullable = true)\n",
      " |-- fk_dim_catalog: string (nullable = true)\n",
      " |-- fk_dim_date: string (nullable = true)\n",
      " |-- fk_dim_customer: string (nullable = true)\n",
      " |-- fk_dim_order: string (nullable = true)\n",
      " |-- order_bi_created_at: string (nullable = true)\n",
      " |-- order_bi_updated_at: string (nullable = true)\n",
      " |-- order_item_bi_created_at: string (nullable = true)\n",
      " |-- order_item_bi_updated_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|dwh_country_id|\n",
      "+-------+--------------+\n",
      "|  count|        175909|\n",
      "|   mean|         276.0|\n",
      "| stddev|           0.0|\n",
      "|    min|           276|\n",
      "|    max|           276|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('dwh_country_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|          channel|fk_sales_order_item|\n",
      "+-----------------+-------------------+\n",
      "|Social Media Paid|              88056|\n",
      "|Social Media Paid|              88055|\n",
      "|Social Media Paid|              88054|\n",
      "|Social Media Paid|              88053|\n",
      "|Social Media Paid|              88052|\n",
      "|Social Media Paid|              88051|\n",
      "|Social Media Paid|              91950|\n",
      "|Social Media Paid|              91949|\n",
      "|Social Media Paid|              91948|\n",
      "|Social Media Paid|              91947|\n",
      "+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"fact_item\")\n",
    "df_clientes.createOrReplaceTempView(\"dim_customer\")\n",
    "users = sqlContext.sql(\"SELECT channel,fk_sales_order_item \\\n",
    "                       FROM fact_item join dim_customer on fk_dim_customer=id_dim_customer limit 10\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perfilamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un perfilamiento de datos para 4 columnas de fact_item que hagan referencia a una métrica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ejercicio SQL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.Ventas (fact_item.paid_price_total_eur) por canal de mercadeo (dim_custome.channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------------------+\n",
      "|             channel|sum(CAST(paid_price_total_eur AS DOUBLE))|\n",
      "+--------------------+-----------------------------------------+\n",
      "|                 SEO|                        3703966.639999915|\n",
      "|       SEM Non Brand|                        978618.4399999831|\n",
      "|                null|                       1916225.2000000416|\n",
      "|             Display|                        299048.4000000016|\n",
      "|               Email|                        292294.3899999953|\n",
      "|              Direct|                        4100295.429999952|\n",
      "|            Referral|                       1825386.8799999857|\n",
      "|         Retargeting|                        93198.88999999981|\n",
      "|   Social Media Paid|                       2265328.2500000363|\n",
      "|           SEM Brand|                       2096564.8900000483|\n",
      "|Social Media Reta...|                        83203.26000000064|\n",
      "| Social Media Unpaid|                       427908.69000000384|\n",
      "|        Other Unpaid|                       232315.44999999757|\n",
      "+--------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"fact_item\")\n",
    "df_clientes.createOrReplaceTempView(\"dim_customer\")\n",
    "users = sqlContext.sql(\"SELECT channel, SUM(paid_price_total_eur) \\\n",
    "                       FROM fact_item join dim_customer on fk_dim_customer=id_dim_customer GROUP BY channel\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.Número de clientes por método de pago (dim_order.payment_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|numeroClientes|      payment_method|\n",
      "+--------------+--------------------+\n",
      "|           275|           NoPayment|\n",
      "|           833|                 COD|\n",
      "|          1463|   Adyen_DirectDebit|\n",
      "|          4102|    Adyen_CreditCard|\n",
      "|             7|Adyen_PaypalRecur...|\n",
      "|          5100|        Adyen_Paypal|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order.createOrReplaceTempView(\"dim_order\")\n",
    "df.createOrReplaceTempView(\"fact_item\")\n",
    "users = sqlContext.sql(\"SELECT COUNT(DISTINCT fk_dim_order) as numeroClientes, payment_method \\\n",
    "                       FROM fact_item join dim_order on fk_dim_order=id_dim_order GROUP BY payment_method\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.Ranking de productores (dim_catalog.producer) por ventas (fact_item.paid_price_total_eur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            producer|            ventas|\n",
      "+--------------------+------------------+\n",
      "|                null|148963.20999999714|\n",
      "|Premium Frischeha...| 36086.92000000164|\n",
      "|            Bonativo|23250.919999999896|\n",
      "|   Bio Frischehandel| 21091.59999999932|\n",
      "|Fleischerei Erchi...| 15254.66999999988|\n",
      "|Landfleischerei R...| 14971.79999999999|\n",
      "|     Blomeyer's Käse|13623.400000000085|\n",
      "|     Ökohof Kuhhorst| 8423.879999999925|\n",
      "|         BioBackHaus| 8183.139999999915|\n",
      "|  Ökohof Lemke&Kluge| 7849.339999999884|\n",
      "|    Ökodorf Brodowin| 6470.149999999893|\n",
      "|   Die Müritzfischer|  6383.88999999997|\n",
      "|         Hemme Milch| 6009.739999999879|\n",
      "|Gemüsebaubetrieb ...| 5147.670000000027|\n",
      "|  Fleischerei Bünger| 4824.249999999999|\n",
      "|       Bauer Nietsch| 4511.310000000089|\n",
      "|   Gläserne Molkerei| 4341.169999999968|\n",
      "|Bauernkäserei Wol...|4020.1799999999826|\n",
      "|Ökohof Teltower R...|3871.1699999999155|\n",
      "|Berliner Lachsman...|3218.0399999999972|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"fact_item\")\n",
    "df_catalog.createOrReplaceTempView(\"dim_catalog\")\n",
    "users = sqlContext.sql(\"SELECT producer, SUM(paid_price_eur) as ventas  \\\n",
    "                       FROM fact_item join dim_catalog on fk_dim_catalog=id_catalog GROUP BY producer ORDER BY ventas DESC\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Ranking de clientes por ventas (fact_item.paid_price_total_eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|id_dim_customer|            ventas|\n",
      "+---------------+------------------+\n",
      "|           1265| 4097.139999999961|\n",
      "|           5416| 3990.409999999939|\n",
      "|           3654|3367.3500000000004|\n",
      "|           2750| 3226.549999999975|\n",
      "|           5144| 3061.189999999996|\n",
      "|            535|2548.0499999999956|\n",
      "|            586|2326.9699999999907|\n",
      "|           5064| 2179.300000000002|\n",
      "|           3407| 2056.279999999994|\n",
      "|           2751|2031.3100000000184|\n",
      "|           1964|1850.9700000000053|\n",
      "|            946|1672.7800000000045|\n",
      "|           3445| 1640.970000000001|\n",
      "|           2493|1491.4900000000073|\n",
      "|           5557|1487.5599999999986|\n",
      "|           1603|1407.6300000000035|\n",
      "|           5202|1350.0400000000036|\n",
      "|            516|1347.8800000000065|\n",
      "|            726|1320.0600000000036|\n",
      "|            332|1284.7000000000064|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "users = sqlContext.sql(\"SELECT id_dim_customer, SUM(paid_price_eur) as ventas  \\\n",
    "                       FROM fact_item join dim_customer on fk_dim_customer=id_dim_customer GROUP BY id_dim_customer ORDER BY ventas DESC\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Número de órdenes con más de 3 items y con valor pagado por item mayor a 30 euros (fact_item.paid_price_total_eur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = sqlContext.sql(\"SELECT fk_dim_order,count(*)  \\\n",
    "                       FROM fact_item  WHERE paid_price_eur >30 GROUP BY fk_dim_order HAVING COUNT(*) >3  \")\n",
    "users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             channel|        sum(valor)|\n",
      "+--------------------+------------------+\n",
      "|                 SEO| 70365.44000000469|\n",
      "|       SEM Non Brand| 13149.76000000005|\n",
      "|                null| 34338.39999999966|\n",
      "|             Display|1887.8199999999877|\n",
      "|               Email| 5847.640000000024|\n",
      "|              Direct| 90341.00000000632|\n",
      "|            Referral|30122.369999999475|\n",
      "|         Retargeting|1730.1499999999953|\n",
      "|   Social Media Paid| 12011.97000000004|\n",
      "|           SEM Brand| 49080.40000000063|\n",
      "|Social Media Reta...|1767.8299999999988|\n",
      "| Social Media Unpaid| 7765.760000000012|\n",
      "|        Other Unpaid|  7854.54000000006|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "df2=df.withColumn(\"valor\",df.paid_price_net_eur.cast(DoubleType()))\n",
    "\n",
    "joindf=df_clientes.join(df2, df2.fk_dim_customer == df_clientes.id_dim_customer)\n",
    "\n",
    "users = joindf.select(\"channel\", \"valor\").groupBy(\"channel\").sum(\"valor\")\n",
    "\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|id_dim_customer|     ventasTotales|\n",
      "+---------------+------------------+\n",
      "|           1265|3820.5499999999915|\n",
      "|           5416| 3699.800000000018|\n",
      "|           3654| 3081.760000000001|\n",
      "|           2750| 3011.999999999993|\n",
      "|           5144|2855.6599999999867|\n",
      "|            535|2362.8800000000065|\n",
      "|            586|2090.4400000000105|\n",
      "|           5064|2034.4099999999987|\n",
      "|           3407|  1914.04999999998|\n",
      "|           2751|1889.9899999999936|\n",
      "|           1964|1662.9399999999964|\n",
      "|           3445|1523.5600000000004|\n",
      "|            946|1498.3500000000042|\n",
      "|           2493| 1378.799999999996|\n",
      "|           5557|1372.2599999999984|\n",
      "|           1603| 1306.969999999998|\n",
      "|           5202|1261.2499999999993|\n",
      "|            516|1256.4799999999996|\n",
      "|            726|1228.3600000000008|\n",
      "|            332|1199.0199999999988|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.withColumn(\"ventas\",df.paid_price_net_eur.cast(DoubleType()))\n",
    "\n",
    "consulta = df_clientes.join(df2, df_clientes.id_dim_customer == df2.fk_dim_customer).groupBy(\"id_dim_customer\")\\\n",
    "            .sum(\"ventas\")\\\n",
    "            .withColumnRenamed(\"sum(ventas)\",\"ventasTotales\")\\\n",
    "            .orderBy(\"ventasTotales\",ascending=False) \n",
    "consulta.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elija dos de las preguntas del punto anterior y respóndalas utilizando las funciones de PySpark\n",
    "http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html\n",
    "https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
